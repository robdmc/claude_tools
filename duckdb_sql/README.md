# DuckDB SQL Query Skill

A Claude Code skill for generating DuckDB SQL queries across DuckDB databases, CSV files, and Parquet files.

## What This Skill Does

This skill helps you:
- Generate SQL queries from plain English questions
- Explore and understand data structures in .ddb, .csv, and .parquet files
- Modify and review existing SQL queries
- Document your data sources with an evolving data dictionary

Queries are **display-only by default** - you review and run them yourself. Execution only happens when explicitly requested.

## Prerequisites

- DuckDB CLI must be installed and available on PATH
- Verify with: `duckdb -version`

## Supported File Types

| File Type | Extension | Description |
|-----------|-----------|-------------|
| DuckDB Database | `.ddb` | Native DuckDB files with multiple tables |
| CSV | `.csv` | Single table per file, schema auto-inferred |
| Parquet | `.parquet` | Single table per file, schema embedded |

You can also use glob patterns (e.g., `logs/*.csv`) to include multiple files.

## Usage

Once installed, the skill activates automatically when you ask Claude questions about:
- DuckDB queries
- Data analysis on .ddb, .csv, or .parquet files
- Exploring data structures

### First Time Setup

When you first use the skill in a project, it will:
1. Ask which data files to document (.ddb, .csv, .parquet, or glob patterns)
2. For glob patterns, ask if files should be separate tables or combined
3. Ask if you have supplementary documentation (code, READMEs, etc.)
4. Generate assets in `duckdb_sql_assets/` directory
5. Detect likely enum columns and ask for your approval to add them

### Example Questions

**Discovery:**
- "What tables are in my DuckDB files?"
- "What columns does the customers table have?"
- "Where is order total stored?"

**Query Generation** (displays query plan first, then SQL after approval):
- "Show me all customers who placed orders in March"
- "Count orders by status"
- "Join customers with orders to see purchase history"

**Execution** (only when explicitly requested):
- "Run this query"
- "Execute it and show me the results"

**Modifications:**
- "Add a date filter to this query"
- "Group these results by month"

## Generated Assets

The skill creates and maintains these files in `duckdb_sql_assets/`:

| File | Purpose |
|------|---------|
| `tables_inventory.json` | Manifest of source files, types, and table metadata |
| `schema_<tablename>.sql` | Schema for each source file (one per .ddb, .csv, or .parquet) |
| `data_dictionary.md` | Semantic documentation (AI + user enhanced, editable) |

### Asset Workflow

1. **Schema files** are auto-generated from your data files
   - `.ddb`: Native schema via DuckDB `.schema` command
   - `.csv`: Schema inferred by DuckDB auto-detection
   - `.parquet`: Schema extracted from embedded metadata
2. **Discovered facts** are presented for approval during conversations
3. **You approve** facts before they're added to the data dictionary
4. **Data dictionary** grows over time with verified information

## Updating Assets

### Add a new data file
Tell the skill:
- "Add sales.ddb to the assets"
- "Add transactions.csv to the assets"
- "Add events.parquet to the assets"
- "Add logs/*.csv to the assets" (glob pattern)

### Remove a data file
The skill will detect missing files and ask to clean up

### Refresh after schema changes
Tell the skill: "Refresh the schema" or "Check for schema changes"

## Learning About Your Data

As you use the skill, it learns facts about your data:
- Column purposes
- Relationships between tables
- Type conversion requirements
- Business logic patterns

When the skill discovers new information, it will ask if you want to add it to the data dictionary:
- **For 1-2 discoveries**: Asked inline during the conversation
- **For 3+ discoveries**: Presented as a summary for bulk approval
- **You can always**: Request to see the diff first before approving

Facts you approve are added directly to `data_dictionary.md`, which you can also edit manually at any time.

## Multi-File Queries

**Across .ddb files** (uses ATTACH):
```sql
ATTACH IF NOT EXISTS '/path/to/other.ddb' AS _db_other (READ_ONLY);
SELECT * FROM main_table JOIN _db_other.other_table ON ...;
```

**Across CSV/Parquet files** (direct file paths):
```sql
SELECT * FROM '/path/to/orders.csv' o
JOIN '/path/to/customers.parquet' c ON o.customer_id = c.id;
```

**Mixed .ddb + CSV/Parquet**:
```sql
-- From a DuckDB database, join to a CSV file
SELECT c.name, t.amount
FROM customers c
JOIN '/path/to/transactions.csv' t ON c.id = t.customer_id;
```

**Glob patterns** (multiple files as one table):
```sql
SELECT * FROM '/path/to/logs/*.csv';
```